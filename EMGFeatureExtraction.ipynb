{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.csv', '00.csv', '000.csv', '0000.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "print(os.listdir(\"1-4sessions/0-free\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emg(path):\n",
    "    sessions_csv = []\n",
    "    for path, _, files in os.walk(path):\n",
    "        for name in files:\n",
    "            sessions_csv.append(os.path.join(path, name))\n",
    "\n",
    "    data = pd.concat([pd.read_csv(file, header = None) for file in sessions_csv]).values\n",
    "    print('input shape', data.shape)\n",
    "    \n",
    "    # reshape data\n",
    "    # one column - one channel\n",
    "    data_x = data[:,:-1]\n",
    "    data_y = data[:,-1]\n",
    "    data_x = data_x.reshape((-1, 8))\n",
    "    data_y = data_y.repeat(8)\n",
    "    data_y = data_y.reshape((-1,1))\n",
    "    data = np.concatenate((data_x, data_y), axis=1)\n",
    "    print('All sessions shape: ', data.shape)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emg_windowing(data, window_size):\n",
    "    data_x = data[:,:-1]\n",
    "    data_y = data[:,-1]\n",
    "    n, m = data_x.shape\n",
    "#     print('shape: ', n, m)\n",
    "    size = n * m\n",
    "#     print('size: ', size)\n",
    "    residual_rows_num =  n % window_size\n",
    "#     print('delete ', residual_rows_num, 'rows')\n",
    "    if residual_rows_num != 0:\n",
    "        data_x = data_x[:-residual_rows_num,:]\n",
    "        data_y = data_y[:-residual_rows_num]\n",
    "#     print('data_x: ', data_x.shape)\n",
    "#     print('data_y: ', data_y.shape)\n",
    "    data_x = data_x.reshape((-1, m * window_size))\n",
    "    \n",
    "    data_y = data_y.reshape((-1, window_size))\n",
    "    data_y = np.array(list(map(np.mean, data_y)))\n",
    "#     print('data_x: ', data_x.shape)\n",
    "#     print('data_y: ', data_y.shape)\n",
    "    \n",
    "    mixed_classes_idxs = np.where(data_y % 1 != 0)\n",
    "#     print('mixed_classes_idxs: ', mixed_classes_idxs)\n",
    "#     print(mixed_classes_idxs[0])\n",
    "    \n",
    "    data = np.c_[data_x, data_y]\n",
    "    data = np.delete(data, mixed_classes_idxs, 0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def integrated_absolute_value(segment):\n",
    "    return sum([abs(s) for s in segment])\n",
    "\n",
    "def mean_absolute_value(segment):\n",
    "    return sum([abs(s) for s in segment])/len(segment)\n",
    "\n",
    "def waveform_length(segment):\n",
    "    n = len(segment)\n",
    "    wl = 0\n",
    "    for i in range(1, n):\n",
    "        wl += abs(segment[i] - segment[i-1])\n",
    "    return wl\n",
    "\n",
    "def zero_crossing(segment):\n",
    "    n = len(segment)\n",
    "    zc = 0\n",
    "    for i in range(n - 1):\n",
    "        if segment[i] * segment[i+1] < 0:\n",
    "            zc += 1\n",
    "    return zc\n",
    "\n",
    "def slope_sign_changes(segment):\n",
    "    n = len(segment)\n",
    "    ssc = 0\n",
    "    for i in range(1, n-1):\n",
    "        if segment[i-1] < segment[i] and segment[i] > segment[i+1] or segment[i-1] > segment[i] and segment[i] < segment[i+1]:\n",
    "            ssc += 1\n",
    "    return ssc\n",
    "\n",
    "def root_mean_square(segment):\n",
    "    return math.sqrt(sum([s*s for s in segment])/len(segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nitime.algorithms.autoregressive import AR_est_LD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def autoregression_coefficients(emg, order):\n",
    "    coef = AR_est_LD(emg, order=order)[0]\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(data_x, channels_num):\n",
    "    n, m = data_x.shape\n",
    "    features = []\n",
    "    \n",
    "    for channel in range(channels_num):\n",
    "        channel_features = []\n",
    "        \n",
    "        # Calculate MAV, ZC, SSC, WL features\n",
    "        channel_features.append(list(map(mean_absolute_value, data_x[:,channel::channels_num])))\n",
    "        channel_features.append(list(map(waveform_length, data_x[:,channel::channels_num])))\n",
    "        channel_features.append(list(map(zero_crossing, data_x[:,channel::channels_num])))\n",
    "        channel_features.append(list(map(slope_sign_changes, data_x[:,channel::channels_num])))\n",
    "        \n",
    "        # calculate AR6 coefficients\n",
    "        ar_order = 6\n",
    "        ar_coef = np.array(list(map(lambda x: autoregression_coefficients(x, ar_order), data_x[:,channel::channels_num])))\n",
    "        channel_features += ar_coef.transpose().tolist()\n",
    "        features += channel_features\n",
    "    \n",
    "    return np.array(features).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (4788, 65)\n",
      "All sessions shape:  (38304, 9)\n",
      "input shape (1214, 65)\n",
      "All sessions shape:  (9712, 9)\n",
      "Features train shape: (954, 80)\n",
      "Features test shape: (239, 80)\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "random.seed(101)\n",
    "data_train = read_emg('1-4sessions')\n",
    "emg_train_windows = emg_windowing(data_train, 40)\n",
    "\n",
    "data_test = read_emg('5session')\n",
    "emg_test_windows = emg_windowing(data_test, 40)\n",
    "\n",
    "data_train_x = emg_train_windows[:,:-1]\n",
    "data_train_y = emg_train_windows[:,-1]\n",
    "features_train = calculate_features(data_train_x, 8)\n",
    "\n",
    "data_test_x = emg_test_windows[:,:-1]\n",
    "data_test_y = emg_test_windows[:,-1]\n",
    "features_test = calculate_features(data_test_y, 8)\n",
    "\n",
    "print('Features train shape:', features_train.shape)\n",
    "print('Features test shape:', features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9330543933054394\n"
     ]
    }
   ],
   "source": [
    "# train_x, test_x, train_y, test_y = train_test_split(features, data_y, test_size=0.3)\n",
    "\n",
    "# Create svm Classifier\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(features_train, data_train_y)\n",
    "pred_y = clf.predict(features_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(data_test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
